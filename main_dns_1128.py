import dataclasses
import enum
import logging
import pathlib
import time
import threading
from datetime import datetime

import numpy as np
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éGUIåç«¯
import matplotlib.pyplot as plt
# ä½¿ç”¨æœ¬åœ°æ–‡ä»¶ï¼Œä¸ä¾èµ–openpi_client
import websocket_client_policy as _websocket_client_policy
import polars as pl
import rich
import tqdm
import tyro

# ROS2å¯¼å…¥
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import JointState, Image
from cv_bridge import CvBridge
import cv2

logger = logging.getLogger(__name__)

# å…¨å±€ROSèŠ‚ç‚¹å’Œæ•°æ®
ros_node = None
latest_joint_state = None
latest_image = None
latest_wrist_image = None
# è®°å½•æ•°æ®æ—¶é—´æˆ³ï¼ˆç”¨äºç›‘æ§æ•°æ®æ–°é²œåº¦ï¼‰
latest_joint_state_time = None
latest_image_time = None
latest_wrist_image_time = None
cv_bridge = CvBridge()
ros_spin_thread = None
ros_spin_active = False


class EnvMode(enum.Enum):
    """Supported environments."""

    ALOHA = "aloha"
    ALOHA_SIM = "aloha_sim"
    DROID = "droid"
    LIBERO = "libero"
    THU_VLNA = "thu_vlna"


@dataclasses.dataclass
class Args:
    """Command line arguments."""

    # Host and port to connect to the server (é€šè¿‡SSHéš§é“)
    host: str = "127.0.0.1"  # è¿æ¥æœ¬åœ°ï¼Œé€šè¿‡SSHéš§é“è½¬å‘
    # Port to connect to the server. If None, the server will use the default port.
    port: int | None = 6006  # æœ¬åœ°è½¬å‘ç«¯å£
    # API key to use for the server.
    api_key: str | None = None
    # Number of steps to run the policy for.
    num_steps: int = 300
    # Path to save the timings to a parquet file. (e.g., timing.parquet)
    timing_file: pathlib.Path | None = None
    # Path to save the actions to a pickle file. (e.g., actions_output.pkl)
    actions_file: pathlib.Path | None = pathlib.Path("actions_output.pkl")
    # Environment to run the policy in.
    env: EnvMode = EnvMode.THU_VLNA  # ä½¿ç”¨THU_VLNAè·å–ROSæ•°æ®
    # Whether to publish actions to /joint_states topic
    publish_actions: bool = True  # æ˜¯å¦å‘å¸ƒactionåˆ°ROSè¯é¢˜ï¼ˆæ”¹ä¸ºFalseé»˜è®¤å…³é—­ï¼‰
    # Action execution frequency (Hz)
    data_freq: float = 15.0  # æ•°æ®é¢‘ç‡ï¼Œé»˜è®¤15Hz
    # Number of actions to execute per request
    actions_per_request: int = 5  # æ¯æ¬¡è¯·æ±‚åæ‰§è¡Œå¤šå°‘ä¸ªaction
    # Output directory for plots
    output_dir: pathlib.Path = pathlib.Path(".")  # è¾“å‡ºç›®å½•


class TimingRecorder:
    """Records timing measurements for different keys."""

    def __init__(self) -> None:
        self._timings: dict[str, list[float]] = {}

    def record(self, key: str, time_ms: float) -> None:
        """Record a timing measurement for the given key."""
        if key not in self._timings:
            self._timings[key] = []
        self._timings[key].append(time_ms)

    def get_stats(self, key: str) -> dict[str, float]:
        """Get statistics for the given key."""
        times = self._timings[key]
        return {
            "mean": float(np.mean(times)),
            "std": float(np.std(times)),
            "p25": float(np.quantile(times, 0.25)),
            "p50": float(np.quantile(times, 0.50)),
            "p75": float(np.quantile(times, 0.75)),
            "p90": float(np.quantile(times, 0.90)),
            "p95": float(np.quantile(times, 0.95)),
            "p99": float(np.quantile(times, 0.99)),
        }

    def print_all_stats(self) -> None:
        """Print statistics for all keys in a concise format."""

        table = rich.table.Table(
            title="[bold blue]Timing Statistics[/bold blue]",
            show_header=True,
            header_style="bold white",
            border_style="blue",
            title_justify="center",
        )

        # Add metric column with custom styling
        table.add_column("Metric", style="cyan", justify="left", no_wrap=True, width=20)

        # Add statistical columns with consistent styling
        stat_columns = [
            ("Mean", "yellow", "mean"),
            ("Std", "yellow", "std"),
            ("P25", "magenta", "p25"),
            ("P50", "magenta", "p50"),
            ("P75", "magenta", "p75"),
            ("P90", "magenta", "p90"),
            ("P95", "magenta", "p95"),
            ("P99", "magenta", "p99"),
        ]

        for name, style, _ in stat_columns:
            table.add_column(name, justify="right", style=style, no_wrap=True, width=8)

        # Add rows for each metric with formatted values
        for key in sorted(self._timings.keys()):
            stats = self.get_stats(key)
            values = [f"{stats[key]:>7.1f}" for _, _, key in stat_columns]
            table.add_row(key, *values)

        # Print with custom console settings
        console = rich.console.Console(width=None, highlight=True)
        console.print(table)

    def write_parquet(self, path: pathlib.Path) -> None:
        """Save the timings to a parquet file."""
        logger.info(f"Writing timings to {path}")
        frame = pl.DataFrame(self._timings)
        path.parent.mkdir(parents=True, exist_ok=True)
        frame.write_parquet(path)


def _get_timestamp() -> str:
    """è·å–å½“å‰æ—¶é—´æˆ³å­—ç¬¦ä¸²"""
    return datetime.now().strftime("%Y%m%d_%H%M%S")


def _plot_actions(actions: np.ndarray, save_path: pathlib.Path, timestamp: str) -> None:
    """ç»˜åˆ¶actionæ›²çº¿å›¾ (å›¾1: æ‰§è¡Œçš„åŠ¨ä½œè½¨è¿¹)

    Args:
        actions: shape=(num_steps, num_joints), æ¯æ­¥çš„å…³èŠ‚åŠ¨ä½œ
        save_path: åŸºç¡€ä¿å­˜è·¯å¾„
        timestamp: æ—¶é—´æˆ³
    """
    num_steps, num_joints = actions.shape

    # åˆ›å»ºå›¾å½¢
    fig, axes = plt.subplots(num_joints, 1, figsize=(14, 2.5 * num_joints), sharex=True)
    if num_joints == 1:
        axes = [axes]

    # å…³èŠ‚åç§°
    joint_names = [f'Joint {i+1}' for i in range(num_joints)]
    if num_joints == 7:
        joint_names = ['Joint 1', 'Joint 2', 'Joint 3', 'Joint 4', 'Joint 5', 'Joint 6', 'Gripper']

    # æ—¶é—´è½´ï¼ˆæ­¥æ•°ï¼‰
    time_steps = np.arange(num_steps)

    # ä¸ºæ¯ä¸ªå…³èŠ‚ç»˜åˆ¶æ›²çº¿
    for i, (ax, name) in enumerate(zip(axes, joint_names)):
        ax.plot(time_steps, actions[:, i], 'b-', linewidth=1.5, label='Executed Action')
        ax.set_ylabel('Rad', fontsize=10)
        ax.set_title(name, fontsize=11, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(loc='upper right', fontsize=8)

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        mean_val = actions[:, i].mean()
        std_val = actions[:, i].std()
        min_val = actions[:, i].min()
        max_val = actions[:, i].max()
        ax.text(0.02, 0.98, f'Î¼={mean_val:.3f}, Ïƒ={std_val:.3f}\nmin={min_val:.3f}, max={max_val:.3f}',
                transform=ax.transAxes, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5), fontsize=8)

    # è®¾ç½®xè½´æ ‡ç­¾
    axes[-1].set_xlabel('Step', fontsize=11)

    # æ€»æ ‡é¢˜
    fig.suptitle(f'Executed Action Trajectories (Total Steps: {num_steps})\n{timestamp}',
                 fontsize=14, fontweight='bold')

    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()

    # ä¿å­˜å›¾ç‰‡
    plot_path = save_path.parent / f"plot1_executed_actions_{timestamp}.png"
    plt.savefig(plot_path, dpi=150, bbox_inches='tight')
    plt.close(fig)

    logger.info(f"âœ… å›¾1 å·²ä¿å­˜: {plot_path}")


def _plot_comparison(executed_actions: np.ndarray, actual_positions: np.ndarray,
                     save_path: pathlib.Path, timestamp: str) -> None:
    """ç»˜åˆ¶å¯¹æ¯”å›¾ (å›¾2: æ‰§è¡ŒåŠ¨ä½œ vs å®é™…å…³èŠ‚ä½ç½®)

    Args:
        executed_actions: shape=(num_steps, num_joints), å‘é€çš„åŠ¨ä½œæŒ‡ä»¤
        actual_positions: shape=(num_steps, num_joints), å®é™…å…³èŠ‚åé¦ˆä½ç½®
        save_path: åŸºç¡€ä¿å­˜è·¯å¾„
        timestamp: æ—¶é—´æˆ³
    """
    num_steps, num_joints = executed_actions.shape

    # åˆ›å»ºå›¾å½¢
    fig, axes = plt.subplots(num_joints, 1, figsize=(14, 2.5 * num_joints), sharex=True)
    if num_joints == 1:
        axes = [axes]

    # å…³èŠ‚åç§°
    joint_names = [f'Joint {i+1}' for i in range(num_joints)]
    if num_joints == 7:
        joint_names = ['Joint 1', 'Joint 2', 'Joint 3', 'Joint 4', 'Joint 5', 'Joint 6', 'Gripper']

    # æ—¶é—´è½´ï¼ˆæ­¥æ•°ï¼‰
    time_steps = np.arange(num_steps)

    # ä¸ºæ¯ä¸ªå…³èŠ‚ç»˜åˆ¶æ›²çº¿
    for i, (ax, name) in enumerate(zip(axes, joint_names)):
        ax.plot(time_steps, executed_actions[:, i], 'b-', linewidth=1.5,
                label='Command (Executed Action)', alpha=0.8)
        ax.plot(time_steps, actual_positions[:, i], 'r--', linewidth=1.5,
                label='Feedback (Actual Position)', alpha=0.8)

        ax.set_ylabel('Rad', fontsize=10)
        ax.set_title(name, fontsize=11, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(loc='upper right', fontsize=8)

        # è®¡ç®—è·Ÿè¸ªè¯¯å·®
        error = np.abs(executed_actions[:, i] - actual_positions[:, i])
        mean_error = error.mean()
        max_error = error.max()
        ax.text(0.02, 0.98, f'Mean Error: {mean_error:.4f}\nMax Error: {max_error:.4f}',
                transform=ax.transAxes, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='lightcyan', alpha=0.5), fontsize=8)

    # è®¾ç½®xè½´æ ‡ç­¾
    axes[-1].set_xlabel('Step', fontsize=11)

    # æ€»æ ‡é¢˜
    fig.suptitle(f'Command vs Actual Position Comparison (Total Steps: {num_steps})\n{timestamp}',
                 fontsize=14, fontweight='bold')

    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()

    # ä¿å­˜å›¾ç‰‡
    plot_path = save_path.parent / f"plot2_comparison_{timestamp}.png"
    plt.savefig(plot_path, dpi=150, bbox_inches='tight')
    plt.close(fig)

    logger.info(f"âœ… å›¾2 å·²ä¿å­˜: {plot_path}")


def _plot_request_actions(request_records: list, save_path: pathlib.Path, timestamp: str) -> None:
    """ç»˜åˆ¶è¯·æ±‚actionå¯è§†åŒ– (å›¾3: æ¯æ¬¡è¯·æ±‚çš„actionåºåˆ—ï¼ŒåŒºåˆ†æŠ›å¼ƒ/æ‰§è¡Œ)

    Args:
        request_records: åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—å…¸:
            {
                'request_id': int,
                'actions': np.ndarray (50, 7),
                'skipped_count': int,  # è·³è¿‡çš„æ•°é‡
                'executed_indices': list,  # å®é™…æ‰§è¡Œçš„ç´¢å¼•
                'global_start_step': int,  # åœ¨å…¨å±€æ—¶é—´è½´ä¸Šçš„èµ·å§‹æ­¥
            }
        save_path: åŸºç¡€ä¿å­˜è·¯å¾„
        timestamp: æ—¶é—´æˆ³
    """
    if len(request_records) == 0:
        logger.warning("æ²¡æœ‰è¯·æ±‚è®°å½•ï¼Œè·³è¿‡å›¾3ç»˜åˆ¶")
        return

    num_joints = request_records[0]['actions'].shape[1]

    # åˆ›å»ºå›¾å½¢
    fig, axes = plt.subplots(num_joints, 1, figsize=(16, 2.5 * num_joints), sharex=True)
    if num_joints == 1:
        axes = [axes]

    # å…³èŠ‚åç§°
    joint_names = [f'Joint {i+1}' for i in range(num_joints)]
    if num_joints == 7:
        joint_names = ['Joint 1', 'Joint 2', 'Joint 3', 'Joint 4', 'Joint 5', 'Joint 6', 'Gripper']

    # é¢œè‰²æ˜ å°„
    colors = plt.cm.tab10(np.linspace(0, 1, min(len(request_records), 10)))

    for i, (ax, name) in enumerate(zip(axes, joint_names)):
        for req_idx, record in enumerate(request_records):
            actions = record['actions']
            skipped = record['skipped_count']
            executed_indices = record['executed_indices']
            global_start = record['global_start_step']
            request_id = record['request_id']

            color = colors[req_idx % len(colors)]

            # è®¡ç®—å…¨å±€æ—¶é—´è½´
            num_actions = len(actions)

            # ç»˜åˆ¶è¢«è·³è¿‡çš„éƒ¨åˆ†ï¼ˆè™šçº¿ï¼Œæµ…è‰²ï¼‰
            if skipped > 0:
                skipped_x = np.arange(global_start, global_start + skipped)
                skipped_y = actions[:skipped, i]
                if len(skipped_x) == len(skipped_y):
                    ax.plot(skipped_x, skipped_y, '--', color=color, alpha=0.3, linewidth=1.0)
                    # ç”¨Xæ ‡è®°è·³è¿‡çš„ç‚¹
                    ax.scatter(skipped_x, skipped_y, color=color, alpha=0.3, s=15, marker='x')

            # ç»˜åˆ¶å®é™…æ‰§è¡Œçš„éƒ¨åˆ†ï¼ˆå®çº¿ï¼Œæ·±è‰²ï¼‰
            if len(executed_indices) > 0:
                exec_x = np.array([global_start + idx for idx in executed_indices])
                exec_y = actions[executed_indices, i]
                ax.plot(exec_x, exec_y, '-', color=color, alpha=0.9, linewidth=1.5,
                       label=f'Req{request_id} (skip:{skipped}, exec:{len(executed_indices)})')
                ax.scatter(exec_x, exec_y, color=color, alpha=0.9, s=20, marker='o')

            # ç»˜åˆ¶è¢«ä¸¢å¼ƒçš„éƒ¨åˆ†ï¼ˆç‚¹çº¿ï¼Œæ›´æµ…ï¼‰
            discarded_start = skipped + len(executed_indices)
            if discarded_start < num_actions:
                discarded_indices = list(range(discarded_start, num_actions))
                discarded_x = np.array([global_start + idx for idx in discarded_indices])
                discarded_y = actions[discarded_indices, i]
                ax.plot(discarded_x, discarded_y, ':', color=color, alpha=0.15, linewidth=0.8)

        ax.set_ylabel('Rad', fontsize=10)
        ax.set_title(name, fontsize=11, fontweight='bold')
        ax.grid(True, alpha=0.3)

        # åªåœ¨ç¬¬ä¸€ä¸ªå­å›¾æ˜¾ç¤ºå›¾ä¾‹
        if i == 0:
            ax.legend(loc='upper right', fontsize=7, ncol=2)

    # è®¾ç½®xè½´æ ‡ç­¾
    axes[-1].set_xlabel('Global Step (with overlap)', fontsize=11)

    # æ·»åŠ å›¾ä¾‹è¯´æ˜
    fig.text(0.02, 0.01,
             'Legend: â”€â”€ Executed (solid)  --- Skipped (dashed+X)  Â·Â·Â· Discarded (dotted, faint)',
             fontsize=9, style='italic')

    # æ€»æ ‡é¢˜
    fig.suptitle(f'Request Action Sequences (Total Requests: {len(request_records)})\n{timestamp}',
                 fontsize=14, fontweight='bold')

    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    plt.subplots_adjust(bottom=0.05)

    # ä¿å­˜å›¾ç‰‡
    plot_path = save_path.parent / f"plot3_request_actions_{timestamp}.png"
    plt.savefig(plot_path, dpi=150, bbox_inches='tight')
    plt.close(fig)

    logger.info(f"âœ… å›¾3 å·²ä¿å­˜: {plot_path}")


def main(args: Args) -> None:
    # ç”Ÿæˆæ—¶é—´æˆ³
    timestamp = _get_timestamp()
    logger.info(f"ğŸ“… è¿è¡Œæ—¶é—´æˆ³: {timestamp}")

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    args.output_dir.mkdir(parents=True, exist_ok=True)

    # å¦‚æœä½¿ç”¨THU_VLNAç¯å¢ƒï¼Œåˆå§‹åŒ–ROSèŠ‚ç‚¹
    if args.env == EnvMode.THU_VLNA:
        logger.info("åˆå§‹åŒ–ROSèŠ‚ç‚¹è·å–çœŸå®æ•°æ®...")
        _init_ros_node()

    obs_fn = {
        EnvMode.ALOHA: _random_observation_aloha,
        EnvMode.ALOHA_SIM: _random_observation_aloha,
        EnvMode.DROID: _random_observation_droid,
        EnvMode.LIBERO: _random_observation_libero,
        EnvMode.THU_VLNA: _observation_thu_vlna,
    }[args.env]

    policy = _websocket_client_policy.WebsocketClientPolicy(
        host=args.host,
        port=args.port,
        api_key=args.api_key,
    )
    logger.info(f"Server metadata: {policy.get_server_metadata()}")

    # Send a few observations to make sure the model is loaded.
    for _ in range(2):
        policy.infer(obs_fn())

    timing_recorder = TimingRecorder()
    executed_actions_list = []  # ä¿å­˜æ‰€æœ‰å®é™…æ‰§è¡Œçš„åŠ¨ä½œ
    actual_positions_list = []  # ã€æ–°å¢ã€‘ä¿å­˜å®é™…å…³èŠ‚ä½ç½®
    request_records = []  # ã€æ–°å¢ã€‘ä¿å­˜æ¯æ¬¡è¯·æ±‚çš„è¯¦ç»†è®°å½•
    action_published = False  # æ ‡è®°æ˜¯å¦å·²æ‰“å°å‘å¸ƒä¿¡æ¯

    # è®¡ç®—æ¯ä¸ªactionçš„æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰
    action_interval = 1.0 / args.data_freq  # 15Hz -> 0.0667s
    logger.info(f"âš™ï¸  æ‰§è¡Œå‚æ•°: é¢‘ç‡={args.data_freq}Hz, é—´éš”={action_interval*1000:.1f}ms, æ¯{args.actions_per_request}ä¸ªactionåè¯·æ±‚æ–°åºåˆ—")

    # Actionç¼“å†²åŒº
    action_buffer = None  # å­˜å‚¨å½“å‰çš„actionåºåˆ— (50, 7)
    action_index = 0  # å½“å‰æ‰§è¡Œåˆ°ç¬¬å‡ ä¸ªaction
    total_executed = 0  # æ€»å…±æ‰§è¡Œçš„actionæ•°
    request_count = 0  # è¯·æ±‚æ¬¡æ•°
    actions_executed_since_request = 0  # ä»ä¸Šæ¬¡è¯·æ±‚å¼€å§‹å·²ç»æ‰§è¡Œäº†å¤šå°‘ä¸ªaction

    # ã€æ–°å¢ã€‘å½“å‰è¯·æ±‚çš„æ‰§è¡Œè®°å½•
    current_request_record = None
    current_executed_indices = []

    # å¼‚æ­¥è¯·æ±‚ç›¸å…³å˜é‡
    next_action_buffer = None  # å­˜å‚¨å¼‚æ­¥è¯·æ±‚è¿”å›çš„æ–°actionåºåˆ—
    request_thread = None  # è¯·æ±‚çº¿ç¨‹
    request_start_time = None  # è¯·æ±‚å¼€å§‹æ—¶é—´
    request_active = False  # æ˜¯å¦æœ‰è¯·æ±‚æ­£åœ¨è¿›è¡Œ
    request_lock = threading.Lock()  # çº¿ç¨‹é”ï¼Œä¿æŠ¤å…±äº«å˜é‡

    def async_request_worker(request_id):
        """åå°çº¿ç¨‹ï¼šå¼‚æ­¥è¯·æ±‚æ–°çš„actionåºåˆ—"""
        nonlocal next_action_buffer, request_active

        try:
            logger.info(f"ğŸ”„ [è¯·æ±‚ {request_id}] åå°çº¿ç¨‹å¼€å§‹è¯·æ±‚...")
            start = time.time()

            # å‘èµ·è¯·æ±‚
            action_response = policy.infer(obs_fn())

            end = time.time()
            inference_time = end - start
            inference_time_ms = inference_time * 1000

            # è®°å½•timing
            timing_recorder.record("client_infer_ms", inference_time_ms)
            for key, value in action_response.get("server_timing", {}).items():
                timing_recorder.record(f"server_{key}", value)
            for key, value in action_response.get("policy_timing", {}).items():
                timing_recorder.record(f"policy_{key}", value)

            # æå–actionåºåˆ—
            if 'actions' in action_response:
                with request_lock:
                    next_action_buffer = {
                        'actions': np.array(action_response['actions']),
                        'inference_time': inference_time,
                        'request_id': request_id
                    }
                logger.info(f"âœ… [è¯·æ±‚ {request_id}] åå°æ¥æ”¶å®Œæˆ: shape={next_action_buffer['actions'].shape}, è€—æ—¶={inference_time_ms:.1f}ms")
            else:
                logger.error(f"âŒ [è¯·æ±‚ {request_id}] è¿”å›æ•°æ®ä¸­æ²¡æœ‰'actions'å­—æ®µ")

        except Exception as e:
            logger.error(f"âŒ [è¯·æ±‚ {request_id}] å¼‚æ­¥è¯·æ±‚å‡ºé”™: {e}")

        finally:
            with request_lock:
                request_active = False

    # é¦–æ¬¡åŒæ­¥è¯·æ±‚ï¼ˆç¡®ä¿æœ‰åˆå§‹æ•°æ®ï¼‰
    logger.info("ğŸ”„ [åˆå§‹åŒ–] åŒæ­¥è¯·æ±‚é¦–ä¸ªactionåºåˆ—...")
    first_response = policy.infer(obs_fn())
    if 'actions' in first_response:
        action_buffer = np.array(first_response['actions'])
        action_index = 0
        logger.info(f"âœ… [åˆå§‹åŒ–] æ”¶åˆ°é¦–ä¸ªåºåˆ—: shape={action_buffer.shape}")

        # ã€æ–°å¢ã€‘è®°å½•é¦–æ¬¡è¯·æ±‚
        current_request_record = {
            'request_id': 0,
            'actions': action_buffer.copy(),
            'skipped_count': 0,
            'executed_indices': [],
            'global_start_step': 0,
        }
        current_executed_indices = []
    else:
        logger.error("âŒ åˆå§‹åŒ–å¤±è´¥ï¼šæ— æ³•è·å–é¦–ä¸ªactionåºåˆ—")
        return

    with tqdm.tqdm(total=args.num_steps, desc="Executing actions") as pbar:
        while total_executed < args.num_steps:
            # æ‰§è¡Œä¸€ä¸ªaction
            action_start = time.time()
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘æ–°çš„å¼‚æ­¥è¯·æ±‚
            if actions_executed_since_request >= args.actions_per_request and not request_active:
                with request_lock:
                    request_active = True
                    request_count += 1
                    request_start_time = time.time()

                # å¯åŠ¨åå°è¯·æ±‚çº¿ç¨‹
                request_thread = threading.Thread(
                    target=async_request_worker,
                    args=(request_count,),
                    daemon=True
                )
                request_thread.start()

            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„actionåºåˆ—åˆ°è¾¾
            with request_lock:
                if next_action_buffer is not None:
                    # ã€æ–°å¢ã€‘ä¿å­˜å½“å‰è¯·æ±‚çš„æ‰§è¡Œè®°å½•
                    if current_request_record is not None:
                        current_request_record['executed_indices'] = current_executed_indices.copy()
                        request_records.append(current_request_record)

                    new_buffer = next_action_buffer
                    next_action_buffer = None  # æ¸…ç©º

                    # è®¡ç®—å»¶è¿Ÿè¡¥å¿
                    inference_time = new_buffer['inference_time']
                    inference_time_ms = inference_time * 1000
                    actions_to_skip = int(inference_time / action_interval)

                    # åˆ‡æ¢åˆ°æ–°buffer
                    action_buffer = new_buffer['actions']
                    action_index = min(actions_to_skip, len(action_buffer) - 1) if actions_to_skip > 0 else 0
                    actions_executed_since_request = 0

                    # ã€æ–°å¢ã€‘åˆ›å»ºæ–°çš„è¯·æ±‚è®°å½•
                    current_request_record = {
                        'request_id': new_buffer['request_id'],
                        'actions': action_buffer.copy(),
                        'skipped_count': action_index,
                        'executed_indices': [],
                        'global_start_step': total_executed - action_index,  # å›æ¨å…¨å±€èµ·å§‹ç‚¹
                    }
                    current_executed_indices = []

                    logger.info(f"ğŸ”„ [åˆ‡æ¢Buffer] è¯·æ±‚{new_buffer['request_id']} | å»¶è¿Ÿ={inference_time_ms:.1f}ms, è·³è¿‡{actions_to_skip}ä¸ªaction, ä»[{action_index}]å¼€å§‹")
                    timing_recorder.record("actions_skipped", actions_to_skip)

            # æ£€æŸ¥bufferæ˜¯å¦è¿˜æœ‰å¯ç”¨çš„action
            if action_index >= len(action_buffer):
                logger.warning(f"âš ï¸  Bufferå·²ç”¨å®Œ (index={action_index}, len={len(action_buffer)})ï¼Œç­‰å¾…æ–°åºåˆ—...")
                time.sleep(action_interval)
                continue



            current_action = action_buffer[action_index]

            # ã€æ–°å¢ã€‘è®°å½•å½“å‰æ‰§è¡Œçš„ç´¢å¼•
            current_executed_indices.append(action_index)

            action_index += 1
            total_executed += 1
            actions_executed_since_request += 1

            # ä¿å­˜æ‰§è¡Œçš„action
            executed_actions_list.append(current_action.copy())

            # ã€æ–°å¢ã€‘ä¿å­˜å®é™…å…³èŠ‚ä½ç½®
            if latest_joint_state is not None:
                actual_positions_list.append(latest_joint_state.copy())
            else:
                # å¦‚æœæ²¡æœ‰åé¦ˆï¼Œç”¨NaNå¡«å……
                actual_positions_list.append(np.full(7, np.nan))

            # æ ¼å¼åŒ–è¾“å‡ºï¼ˆæ¯5ä¸ªæ‰“å°ä¸€æ¬¡ï¼Œé¿å…åˆ·å±ï¼‰
            if total_executed % 5 == 1 or total_executed <= 3:
                action_str = ', '.join([f"{val:+.6f}" for val in current_action])
                logger.info(f"  Step {total_executed:3d} | Buffer[{action_index-1}] | Action: [{action_str}]")

            # å‘å¸ƒactionåˆ°/joint_statesè¯é¢˜
            if args.publish_actions and ros_node is not None:
                if not action_published:
                    logger.info("å¼€å§‹å‘å¸ƒactionåˆ° /joint_states è¯é¢˜...")
                    action_published = True
                ros_node.publish_action(current_action)

            pbar.update(1)

            # ç²¾ç¡®æ§åˆ¶é¢‘ç‡ï¼šå‡å»actionæ‰§è¡Œè€—æ—¶
            action_elapsed = time.time() - action_start
            sleep_time = max(0, action_interval - action_elapsed)
            if sleep_time > 0:
                time.sleep(sleep_time)

    # ã€æ–°å¢ã€‘ä¿å­˜æœ€åä¸€ä¸ªè¯·æ±‚çš„è®°å½•
    if current_request_record is not None:
        current_request_record['executed_indices'] = current_executed_indices.copy()
        request_records.append(current_request_record)

    logger.info(f"\nâœ… æ‰§è¡Œå®Œæˆ! æ€»å…±æ‰§è¡Œ {total_executed} ä¸ªaction, è¯·æ±‚ {request_count} æ¬¡")
    timing_recorder.print_all_stats()

    if args.timing_file is not None:
        timing_recorder.write_parquet(args.timing_file)

    # ä¿å­˜æ‰€æœ‰å®é™…æ‰§è¡Œçš„actionæ•°æ®
    if len(executed_actions_list) > 0 and args.actions_file is not None:
        import pickle

        # å¸¦æ—¶é—´æˆ³çš„pklæ–‡ä»¶å
        pkl_path = args.output_dir / f"actions_output_{timestamp}.pkl"

        # ä¿å­˜æ›´å¤šæ•°æ®
        save_data = {
            'executed_actions': executed_actions_list,
            'actual_positions': actual_positions_list,
            'request_records': request_records,
            'timestamp': timestamp,
            'args': {
                'num_steps': args.num_steps,
                'data_freq': args.data_freq,
                'actions_per_request': args.actions_per_request,
            }
        }

        with open(pkl_path, 'wb') as f:
            pickle.dump(save_data, f)
        logger.info(f"å·²ä¿å­˜æ•°æ®åˆ° {pkl_path}")

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        action_array = np.array(executed_actions_list)
        actual_array = np.array(actual_positions_list)

        logger.info(f"Actionæ•°ç»„å½¢çŠ¶: {action_array.shape}")
        logger.info(f"Actual Positionæ•°ç»„å½¢çŠ¶: {actual_array.shape}")
        logger.info(f"ActionèŒƒå›´: min={action_array.min():.3f}, max={action_array.max():.3f}, mean={action_array.mean():.3f}")

        # ã€ç»˜åˆ¶ä¸‰å¼ å›¾ã€‘
        # å›¾1: æ‰§è¡Œçš„åŠ¨ä½œè½¨è¿¹
        _plot_actions(action_array, pkl_path, timestamp)

        # å›¾2: æ‰§è¡ŒåŠ¨ä½œ vs å®é™…ä½ç½®å¯¹æ¯”
        _plot_comparison(action_array, actual_array, pkl_path, timestamp)

        # å›¾3: è¯·æ±‚actionå¯è§†åŒ–ï¼ˆæŠ›å¼ƒ/æ‰§è¡Œä¸åŒé¢œè‰²ï¼‰
        _plot_request_actions(request_records, pkl_path, timestamp)

    # æ¸…ç†ROSèŠ‚ç‚¹
    global ros_spin_active, ros_spin_thread
    if ros_node is not None:
        # åœæ­¢åå°çº¿ç¨‹
        ros_spin_active = False
        if ros_spin_thread is not None:
            ros_spin_thread.join(timeout=1.0)

        # æ¸…ç†ROSèŠ‚ç‚¹
        ros_node.destroy_node()
        rclpy.shutdown()
        logger.info("ROSèŠ‚ç‚¹å·²å…³é—­")


def _random_observation_aloha() -> dict:
    return {
        "state": np.ones((14,)),
        "images": {
            "cam_high": np.random.randint(256, size=(3, 224, 224), dtype=np.uint8),
            "cam_low": np.random.randint(256, size=(3, 224, 224), dtype=np.uint8),
            "cam_left_wrist": np.random.randint(256, size=(3, 224, 224), dtype=np.uint8),
            "cam_right_wrist": np.random.randint(256, size=(3, 224, 224), dtype=np.uint8),
        },
        "prompt": "do something",
    }


def _random_observation_droid() -> dict:
    return {
        "observation/exterior_image_1_left": np.random.randint(256, size=(224, 224, 3), dtype=np.uint8),
        "observation/wrist_image_left": np.random.randint(256, size=(224, 224, 3), dtype=np.uint8),
        "observation/joint_position": np.random.rand(7),
        "observation/gripper_position": np.random.rand(1),
        "prompt": "do something",
    }


def _random_observation_libero() -> dict:
    return {
        "observation/state": np.random.rand(8),
        "observation/image": np.random.randint(256, size=(224, 224, 3), dtype=np.uint8),
        "observation/wrist_image": np.random.randint(256, size=(224, 224, 3), dtype=np.uint8),
        "prompt": "do something",
    }

def _init_ros_node():
    """åˆå§‹åŒ–ROSèŠ‚ç‚¹å¹¶è®¢é˜…æ•°æ®"""
    global ros_node

    class ROSDataCollector(Node):
        def __init__(self):
            super().__init__('openpi_data_collector')

            # è®¢é˜…å…³èŠ‚çŠ¶æ€
            self.joint_sub = self.create_subscription(
                JointState,
                '/joint_states_single',
                self.joint_callback,
                10
            )

            # è®¢é˜…ä¸»ç›¸æœºå›¾åƒï¼ˆMIIVIIï¼‰
            self.image_sub = self.create_subscription(
                Image,
                '/miivii_gmsl/image0',
                self.image_callback,
                10
            )

            # è®¢é˜…è…•éƒ¨ç›¸æœºï¼ˆRealSenseï¼‰
            self.wrist_image_sub = self.create_subscription(
                Image,
                '/camera/camera/color/image_raw',
                self.wrist_image_callback,
                10
            )

            # åˆ›å»ºPublisherï¼Œå‘å¸ƒæ§åˆ¶æŒ‡ä»¤åˆ°/joint_states
            self.joint_cmd_pub = self.create_publisher(
                JointState,
                '/joint_states',
                10
            )

            self.get_logger().info("ROSèŠ‚ç‚¹å·²åˆå§‹åŒ–ï¼Œç­‰å¾…æ•°æ®...")

        def joint_callback(self, msg):
            global latest_joint_state, latest_joint_state_time
            # åªå–å‰7ä¸ªå…³èŠ‚ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            latest_joint_state = np.array(msg.position[:7])
            latest_joint_state_time = time.time()

        def image_callback(self, msg):
            global latest_image, latest_image_time
            # MIIVIIä¸»ç›¸æœº -> observation/image
            cv_image = cv_bridge.imgmsg_to_cv2(msg, desired_encoding='rgb8')
            latest_image = cv2.resize(cv_image, (224, 224))
            latest_image_time = time.time()

        def wrist_image_callback(self, msg):
            global latest_wrist_image, latest_wrist_image_time
            # RealSenseè…•éƒ¨ç›¸æœº -> observation/wrist_image
            cv_image = cv_bridge.imgmsg_to_cv2(msg, desired_encoding='rgb8')
            latest_wrist_image = cv2.resize(cv_image, (224, 224))
            latest_wrist_image_time = time.time()

        def publish_action(self, action_positions):
            """å‘å¸ƒæ§åˆ¶æŒ‡ä»¤åˆ°/joint_statesè¯é¢˜"""
            msg = JointState()
            msg.header.stamp = self.get_clock().now().to_msg()
            msg.header.frame_id = 'piper_single'
            msg.name = ['joint1', 'joint2', 'joint3', 'joint4', 'joint5', 'joint6', 'joint7']
            msg.position = action_positions.tolist() if isinstance(action_positions, np.ndarray) else action_positions
            msg.velocity = [0.0] * 7  # å¯ä»¥æ ¹æ®éœ€è¦è®¾ç½®é€Ÿåº¦
            msg.effort = [0.0] * 7    # å¯ä»¥æ ¹æ®éœ€è¦è®¾ç½®åŠ›çŸ©

            self.joint_cmd_pub.publish(msg)

    rclpy.init()
    ros_node = ROSDataCollector()

    # å¯åŠ¨åå°çº¿ç¨‹æŒç»­æ¥æ”¶ROSæ•°æ®
    global ros_spin_thread, ros_spin_active
    ros_spin_active = True

    def ros_spin_worker():
        """åå°çº¿ç¨‹æŒç»­spin ROSèŠ‚ç‚¹"""
        while ros_spin_active:
            rclpy.spin_once(ros_node, timeout_sec=0.01)

    ros_spin_thread = threading.Thread(target=ros_spin_worker, daemon=True)
    ros_spin_thread.start()

    # ç­‰å¾…é¦–å¸§æ•°æ®
    logger.info("ç­‰å¾…é¦–å¸§ROSæ•°æ®...")
    time.sleep(0.5)  # ç­‰500msè®©æ•°æ®åˆ°è¾¾

    logger.info("ROSèŠ‚ç‚¹åˆå§‹åŒ–å®Œæˆ")

def _observation_thu_vlna() -> dict:
    """ä»ROSèŠ‚ç‚¹è·å–çœŸå®è§‚æµ‹æ•°æ®"""
    global latest_joint_state, latest_image, latest_wrist_image
    global latest_joint_state_time, latest_image_time, latest_wrist_image_time

    # åå°çº¿ç¨‹å·²ç»åœ¨æŒç»­æ›´æ–°æ•°æ®ï¼Œç›´æ¥è¯»å–æœ€æ–°å€¼å³å¯
    # å¦‚æœè¿˜æ²¡æœ‰æ•°æ®ï¼Œç­‰å¾…æ•°æ®å°±ç»ª
    max_wait = 10.0  # æœ€å¤šç­‰å¾…10ç§’
    wait_start = time.time()
    while latest_joint_state is None or latest_image is None or latest_wrist_image is None:
        missing = []
        if latest_joint_state is None:
            missing.append("å…³èŠ‚çŠ¶æ€")
        if latest_image is None:
            missing.append("ä¸»ç›¸æœº(MIIVII)")
        if latest_wrist_image is None:
            missing.append("è…•éƒ¨ç›¸æœº(RealSense)")

        elapsed = time.time() - wait_start
        if elapsed > max_wait:
            raise RuntimeError(f"ç­‰å¾…ROSæ•°æ®è¶…æ—¶({max_wait}ç§’): {', '.join(missing)}")

        logger.warning(f"â³ ç­‰å¾…ROSæ•°æ® ({elapsed:.1f}s): {', '.join(missing)}")
        time.sleep(0.1)

    # è®¡ç®—æ•°æ®å¹´é¾„ï¼ˆmsï¼‰
    current_time = time.time()
    joint_age_ms = (current_time - latest_joint_state_time) * 1000 if latest_joint_state_time else 999
    image_age_ms = (current_time - latest_image_time) * 1000 if latest_image_time else 999
    wrist_age_ms = (current_time - latest_wrist_image_time) * 1000 if latest_wrist_image_time else 999

    # æ¯10æ­¥æ‰“å°ä¸€æ¬¡æ•°æ®æ–°é²œåº¦ï¼ˆé¿å…åˆ·å±ï¼‰
    if hasattr(_observation_thu_vlna, 'call_count'):
        _observation_thu_vlna.call_count += 1
    else:
        _observation_thu_vlna.call_count = 0

    if _observation_thu_vlna.call_count % 10 == 0:
        logger.info(f"ğŸ“Š æ•°æ®å¹´é¾„ | å…³èŠ‚: {joint_age_ms:.0f}ms, ä¸»ç›¸æœº: {image_age_ms:.0f}ms, è…•ç›¸æœº: {wrist_age_ms:.0f}ms")

    return {
        "observation/state": latest_joint_state,
        "observation/image": latest_image,
        "observation/wrist_image": latest_wrist_image,
        "prompt": "Move the robotic arm, and actuate the end-effector to press the elevator's UP call button.",
    }


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    main(tyro.cli(Args))
